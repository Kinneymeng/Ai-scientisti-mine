\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand*\HyPL@Entry[1]{}
\citation{rajamani2012vehicle}
\HyPL@Entry{0<</S/D>>}
\newlabel{FirstPage}{{}{1}{}{section*.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\newlabel{sec:intro}{{1}{1}{Introduction}{section.1}{}}
\citation{Devos2024ALI}
\citation{Cai2025JointEO}
\citation{Chen2024VehicleSE}
\citation{Hermansdorfer2020EndtoEnd}
\citation{Song2025DataDriven}
\citation{Vaswani2017AttentionIA}
\citation{Dosovitskiy2020AnII}
\citation{Raissi2019PhysicsinformedNN}
\citation{Bellec2023ErrorEA}
\citation{Zhang2025ARF}
\@writefile{toc}{\contentsline {section}{\numberline {2}Related work}{2}{section.2}\protected@file@percent }
\newlabel{sec:related}{{2}{2}{Related work}{section.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Robust parameter estimation under noise}{2}{subsection.2.1}\protected@file@percent }
\newlabel{sec:robust_estimation}{{2.1}{2}{Robust parameter estimation under noise}{subsection.2.1}{}}
\citation{CastelanPerez2025FilteringAF}
\citation{rajamani2012vehicle}
\citation{rajamani2012vehicle}
\citation{Narendra1990IdentificationAC}
\@writefile{toc}{\contentsline {section}{\numberline {3}Background}{3}{section.3}\protected@file@percent }
\newlabel{sec:background}{{3}{3}{Background}{section.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Vehicle dynamics model}{3}{subsection.3.1}\protected@file@percent }
\newlabel{sec:vehicle_model}{{3.1}{3}{Vehicle dynamics model}{subsection.3.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Parameter identification methods}{3}{subsection.3.2}\protected@file@percent }
\newlabel{sec:param_id_methods}{{3.2}{3}{Parameter identification methods}{subsection.3.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Attention mechanisms}{3}{subsection.3.3}\protected@file@percent }
\newlabel{sec:attention}{{3.3}{3}{Attention mechanisms}{subsection.3.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Problem setting}{3}{subsection.3.4}\protected@file@percent }
\newlabel{sec:problem_setting}{{3.4}{3}{Problem setting}{subsection.3.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Method}{4}{section.4}\protected@file@percent }
\newlabel{sec:method}{{4}{4}{Method}{section.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Experimental setup}{4}{section.5}\protected@file@percent }
\newlabel{sec:experimental}{{5}{4}{Experimental setup}{section.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Results}{5}{section.6}\protected@file@percent }
\newlabel{sec:results}{{6}{5}{Results}{section.6}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Parameter identification errors (\%) across different noise levels. Lower values indicate better performance.\relax }}{5}{table.caption.2}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{tab:results}{{1}{5}{Parameter identification errors (\%) across different noise levels. Lower values indicate better performance.\relax }{table.caption.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Mean parameter identification error as a function of measurement noise level. The attention-enhanced neural network maintains consistently low error rates across different noise levels, while the baseline neural network shows a non-monotonic pattern with peak degradation at moderate-high noise levels.\relax }}{5}{figure.caption.3}\protected@file@percent }
\newlabel{fig:noise_sensitivity}{{1}{5}{Mean parameter identification error as a function of measurement noise level. The attention-enhanced neural network maintains consistently low error rates across different noise levels, while the baseline neural network shows a non-monotonic pattern with peak degradation at moderate-high noise levels.\relax }{figure.caption.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Evolution of attention weights during training for each input feature. Each line represents a different run, showing how the attention weight for that feature changed over training epochs.\relax }}{6}{figure.caption.4}\protected@file@percent }
\newlabel{fig:attention_weights}{{2}{6}{Evolution of attention weights during training for each input feature. Each line represents a different run, showing how the attention weight for that feature changed over training epochs.\relax }{figure.caption.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Final converged attention weights for each input feature across all runs. The plot summarizes which features the attention mechanism ultimately deemed most important for parameter identification after training converged.\relax }}{6}{figure.caption.5}\protected@file@percent }
\newlabel{fig:final_attention}{{3}{6}{Final converged attention weights for each input feature across all runs. The plot summarizes which features the attention mechanism ultimately deemed most important for parameter identification after training converged.\relax }{figure.caption.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Comparison of feature importance between baseline neural network and attention-enhanced neural network. The baseline network implicitly assigns equal weights to all features, while the attention mechanism learns that velocity is the most critical feature.\relax }}{6}{figure.caption.6}\protected@file@percent }
\newlabel{fig:feature_importance}{{4}{6}{Comparison of feature importance between baseline neural network and attention-enhanced neural network. The baseline network implicitly assigns equal weights to all features, while the attention mechanism learns that velocity is the most critical feature.\relax }{figure.caption.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Comparison of identified cornering stiffness parameters ($C_f$ and $C_r$) across all experimental runs and methods. True parameter values are shown as red dashed horizontal lines.\relax }}{6}{figure.caption.7}\protected@file@percent }
\newlabel{fig:parameter_comparison}{{5}{6}{Comparison of identified cornering stiffness parameters ($C_f$ and $C_r$) across all experimental runs and methods. True parameter values are shown as red dashed horizontal lines.\relax }{figure.caption.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Box plot comparison of mean parameter identification errors across all methods. The y-axis uses a logarithmic scale to accommodate the wide range of error values observed.\relax }}{7}{figure.caption.8}\protected@file@percent }
\newlabel{fig:error_comparison}{{6}{7}{Box plot comparison of mean parameter identification errors across all methods. The y-axis uses a logarithmic scale to accommodate the wide range of error values observed.\relax }{figure.caption.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Training and validation loss curves for the neural network-based methods. The left subplot shows the standard neural network training dynamics, while the right subplot shows the attention-enhanced neural network training dynamics. Solid lines represent training loss, while dashed lines represent validation loss. The y-axis uses a logarithmic scale to better visualize convergence behavior.\relax }}{7}{figure.caption.9}\protected@file@percent }
\newlabel{fig:training_curves}{{7}{7}{Training and validation loss curves for the neural network-based methods. The left subplot shows the standard neural network training dynamics, while the right subplot shows the attention-enhanced neural network training dynamics. Solid lines represent training loss, while dashed lines represent validation loss. The y-axis uses a logarithmic scale to better visualize convergence behavior.\relax }{figure.caption.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Physics-informed interpretation of attention weights}{7}{subsection.6.1}\protected@file@percent }
\newlabel{sec:physics_interpretation}{{6.1}{7}{Physics-informed interpretation of attention weights}{subsection.6.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Conclusions}{8}{section.7}\protected@file@percent }
\newlabel{sec:conclusion}{{7}{8}{Conclusions}{section.7}{}}
\bibstyle{SageH}
\bibdata{references}
\bibcite{Bellec2023ErrorEA}{{1}{2023}{{Bellec et~al.}}{{}}}
\bibcite{Cai2025JointEO}{{2}{2025}{{Cai et~al.}}{{}}}
\bibcite{CastelanPerez2025FilteringAF}{{3}{2025}{{Castelan-Perez et~al.}}{{}}}
\bibcite{Chen2024VehicleSE}{{4}{2024}{{Chen et~al.}}{{}}}
\bibcite{Devos2024ALI}{{5}{2024}{{Devos et~al.}}{{}}}
\bibcite{Dosovitskiy2020AnII}{{6}{2021}{{Dosovitskiy et~al.}}{{}}}
\bibcite{Hermansdorfer2020EndtoEnd}{{7}{2020}{{Hermansdorfer et~al.}}{{}}}
\bibcite{Narendra1990IdentificationAC}{{8}{1990}{{Narendra and Parthasarathy}}{{}}}
\bibcite{Raissi2019PhysicsinformedNN}{{9}{2019}{{Raissi et~al.}}{{Raissi, Perdikaris and Karniadakis}}}
\bibcite{rajamani2012vehicle}{{10}{2012}{{Rajamani}}{{}}}
\bibcite{Song2025DataDriven}{{11}{2025}{{Song et~al.}}{{}}}
\bibcite{Vaswani2017AttentionIA}{{12}{2017}{{Vaswani et~al.}}{{Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez, Kaiser and Polosukhin}}}
\bibcite{Zhang2025ARF}{{13}{2025}{{Zhang et~al.}}{{}}}
\newlabel{LastPage}{{7}{9}{Conclusions}{section*.13}{}}
