\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{rajamani2012vehicle}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\newlabel{sec:intro}{{1}{1}{Introduction}{section.1}{}}
\citation{Devos2024ALI}
\citation{Cai2025JointEO}
\citation{Chen2024VehicleSE}
\citation{Hermansdorfer2020EndtoEnd}
\citation{Song2025DataDriven}
\citation{Vaswani2017AttentionIA}
\citation{Dosovitskiy2020AnII}
\@writefile{toc}{\contentsline {section}{\numberline {2}Related Work}{2}{section.2}\protected@file@percent }
\newlabel{sec:related}{{2}{2}{Related Work}{section.2}{}}
\citation{Raissi2019PhysicsinformedNN}
\citation{Bellec2023ErrorEA}
\citation{Zhang2025ARF}
\citation{CastelanPerez2025FilteringAF}
\citation{rajamani2012vehicle}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Robust Parameter Estimation under Noise}{3}{subsection.2.1}\protected@file@percent }
\newlabel{sec:robust_estimation}{{2.1}{3}{Robust Parameter Estimation under Noise}{subsection.2.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Background}{3}{section.3}\protected@file@percent }
\newlabel{sec:background}{{3}{3}{Background}{section.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Vehicle Dynamics Model}{3}{subsection.3.1}\protected@file@percent }
\newlabel{sec:vehicle_model}{{3.1}{3}{Vehicle Dynamics Model}{subsection.3.1}{}}
\citation{rajamani2012vehicle}
\citation{Narendra1990IdentificationAC}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Parameter Identification Methods}{4}{subsection.3.2}\protected@file@percent }
\newlabel{sec:param_id_methods}{{3.2}{4}{Parameter Identification Methods}{subsection.3.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Attention Mechanisms}{4}{subsection.3.3}\protected@file@percent }
\newlabel{sec:attention}{{3.3}{4}{Attention Mechanisms}{subsection.3.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Problem Setting}{4}{subsection.3.4}\protected@file@percent }
\newlabel{sec:problem_setting}{{3.4}{4}{Problem Setting}{subsection.3.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Method}{5}{section.4}\protected@file@percent }
\newlabel{sec:method}{{4}{5}{Method}{section.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Experimental Setup}{6}{section.5}\protected@file@percent }
\newlabel{sec:experimental}{{5}{6}{Experimental Setup}{section.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Results}{6}{section.6}\protected@file@percent }
\newlabel{sec:results}{{6}{6}{Results}{section.6}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Parameter identification errors (\%) across different noise levels. Lower values indicate better performance.\relax }}{7}{table.caption.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{tab:results}{{1}{7}{Parameter identification errors (\%) across different noise levels. Lower values indicate better performance.\relax }{table.caption.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Mean parameter identification error as a function of measurement noise level. The attention-enhanced neural network maintains low error rates even at high noise levels, while the baseline neural network's performance degrades significantly as noise increases.\relax }}{8}{figure.caption.2}\protected@file@percent }
\newlabel{fig:noise_sensitivity}{{1}{8}{Mean parameter identification error as a function of measurement noise level. The attention-enhanced neural network maintains low error rates even at high noise levels, while the baseline neural network's performance degrades significantly as noise increases.\relax }{figure.caption.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Evolution of attention weights during training for each input feature. Each line represents a different run, showing how the attention weight for that feature changed over training epochs.\relax }}{8}{figure.caption.3}\protected@file@percent }
\newlabel{fig:attention_weights}{{2}{8}{Evolution of attention weights during training for each input feature. Each line represents a different run, showing how the attention weight for that feature changed over training epochs.\relax }{figure.caption.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Final converged attention weights for each input feature across all runs. The plot summarizes which features the attention mechanism ultimately deemed most important for parameter identification after training converged.\relax }}{9}{figure.caption.4}\protected@file@percent }
\newlabel{fig:final_attention}{{3}{9}{Final converged attention weights for each input feature across all runs. The plot summarizes which features the attention mechanism ultimately deemed most important for parameter identification after training converged.\relax }{figure.caption.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Comparison of identified cornering stiffness parameters ($C_f$ and $C_r$) across all experimental runs and methods. True parameter values are shown as red dashed horizontal lines.\relax }}{9}{figure.caption.5}\protected@file@percent }
\newlabel{fig:parameter_comparison}{{4}{9}{Comparison of identified cornering stiffness parameters ($C_f$ and $C_r$) across all experimental runs and methods. True parameter values are shown as red dashed horizontal lines.\relax }{figure.caption.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Physics-Informed Interpretation of Attention Weights}{9}{subsection.6.1}\protected@file@percent }
\newlabel{sec:physics_interpretation}{{6.1}{9}{Physics-Informed Interpretation of Attention Weights}{subsection.6.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Box plot comparison of mean parameter identification errors across all methods. The y-axis uses a logarithmic scale to accommodate the wide range of error values observed.\relax }}{10}{figure.caption.6}\protected@file@percent }
\newlabel{fig:error_comparison}{{5}{10}{Box plot comparison of mean parameter identification errors across all methods. The y-axis uses a logarithmic scale to accommodate the wide range of error values observed.\relax }{figure.caption.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Training and validation loss curves for the neural network-based methods. Solid lines represent training loss, while dashed lines represent validation loss. The y-axis uses a logarithmic scale.\relax }}{10}{figure.caption.7}\protected@file@percent }
\newlabel{fig:training_curves}{{6}{10}{Training and validation loss curves for the neural network-based methods. Solid lines represent training loss, while dashed lines represent validation loss. The y-axis uses a logarithmic scale.\relax }{figure.caption.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Conclusions}{12}{section.7}\protected@file@percent }
\newlabel{sec:conclusion}{{7}{12}{Conclusions}{section.7}{}}
\bibdata{references}
\bibcite{Bellec2023ErrorEA}{{1}{2023}{{Bellec et~al.}}{{}}}
\bibcite{Cai2025JointEO}{{2}{2025}{{Cai et~al.}}{{}}}
\bibcite{CastelanPerez2025FilteringAF}{{3}{2025}{{Castelan-Perez et~al.}}{{}}}
\bibcite{Chen2024VehicleSE}{{4}{2024}{{Chen et~al.}}{{}}}
\bibcite{Devos2024ALI}{{5}{2024}{{Devos et~al.}}{{}}}
\bibcite{Dosovitskiy2020AnII}{{6}{2021}{{Dosovitskiy et~al.}}{{}}}
\bibcite{Hermansdorfer2020EndtoEnd}{{7}{2020}{{Hermansdorfer et~al.}}{{}}}
\bibcite{Narendra1990IdentificationAC}{{8}{1990}{{Narendra \& Parthasarathy}}{{Narendra and Parthasarathy}}}
\bibcite{Raissi2019PhysicsinformedNN}{{9}{2019}{{Raissi et~al.}}{{Raissi, Perdikaris, and Karniadakis}}}
\bibcite{rajamani2012vehicle}{{10}{2012}{{Rajamani}}{{}}}
\bibcite{Song2025DataDriven}{{11}{2025}{{Song et~al.}}{{}}}
\bibcite{Vaswani2017AttentionIA}{{12}{2017}{{Vaswani et~al.}}{{Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez, Kaiser, and Polosukhin}}}
\bibcite{Zhang2025ARF}{{13}{2025}{{Zhang et~al.}}{{}}}
\bibstyle{iclr2024_conference}
\@writefile{toc}{\contentsline {section}{\numberline {A}Appendix}{14}{appendix.A}\protected@file@percent }
\newlabel{app:appendix}{{A}{14}{Appendix}{appendix.A}{}}
